{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical terms\n",
    "\n",
    "\n",
    "**Probability** - the expected relative frequency of a particular outcome\n",
    "\n",
    "P(heads) = 0.5 --> discrete distribution\n",
    "P(height>69) = 0.3 --> contious distribution\n",
    "\n",
    "**Random variable** (RV) - variable determined by random experiment\n",
    "\n",
    "P(H>h) --> probability that height is larger than some observed height h\n",
    "\n",
    "**Probability distribution, f(h)**\n",
    "- describes the distribution of a random variable\n",
    "- area under pdf fives probability\n",
    "\n",
    "\n",
    "What distribution do we use?\n",
    "* typically assume normal (Gaussian)\n",
    "* functions of normals give other popular distributions\n",
    "- Chisquare is the square of a normal\n",
    "-  T involves a normal and a chisquares\n",
    "-  F is the ratio of two chisquares\n",
    "\n",
    "**Expected value** - the mean of a random variable (E[Y])\n",
    "\n",
    "**Variance** - how the values of the RV are dispersed about the mean\n",
    "**Covariance** - how much 2RV's vary together\n",
    "- $Cov[X,Y] = E[(X - E[X])(Y - E[Y])]$\n",
    "- if two RC's are independent, $Cov[x, Y] = 0$ BUT the oposite is not true \n",
    "\n",
    "**Bias** and **variance** can be used to assess an estimator\n",
    "- **Estimator** - equation that estimates a parameter for you\n",
    "- **Bias**: on average, the estimate is correct\n",
    "- **Variance**: the reliability of the estimate\n",
    "\n",
    "How do we quantify the quality of an estimator?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple linear regression\n",
    "\n",
    "Introduction without matrix algebra.\n",
    "\n",
    "Note: \n",
    "- I'll stick with the terminology of *association* when describing regression results.\n",
    "- *causality* is definitely a different type of approach\n",
    "- Some will debate whether linear regression results can be interpreted as *predictive*\n",
    "\n",
    "Models helps us tell stories! (correlation of age with reaction time)\n",
    "\n",
    "For the ith observation unit\n",
    "\n",
    "$Y_{i} = \\beta_{0} + \\beta_{1} X_{i} + \\epsilon_{i}$\n",
    "\n",
    "- $Y_{i}$: the dependent (random) variable \n",
    "- $X_{i}$: independent variable (not random)\n",
    "- $\\beta_{0}, \\beta_{1}$: model parameters \n",
    "- $\\epsilon_{i}$: Random error, how the observation deviates from the population mean\n",
    "\n",
    "**Fixed**: $\\beta_{0} + \\beta_{1} X_{i}$\n",
    "- Mean of $Y_{i}, (E[Y_{i}])$ \n",
    "\n",
    "**Random**: $\\epsilon_{i}$ --> this is where the variance is desctibed\n",
    "- Variability of $Y_{i}$\n",
    "- $E(\\epsilon_{i}) = 0$ --> variance has a mean of 0 \n",
    "- $Var(\\epsilon_{i} = \\sigma^{2}$ --> variance is the same for each subject\n",
    "- $Cov(\\epsilon_{i}, \\epsilon_{j})=0$ --> subjects are not correlated with each other\n",
    "- it folows that the variance of $Y_i$ is $\\sigma^2$\n",
    "\n",
    "## How do we fit the model?\n",
    "\n",
    "Which line fits the data best?\n",
    "\n",
    "- Minimize the distance between the data and the line (error)\n",
    "- Absolute distance? squared distance?\n",
    "- $\\epsilon_{i} = Y_i - (\\beta_0+\\beta_{1}X_{1})$\n",
    "\n",
    "\n",
    "### Least Squares\n",
    "- minimize squared differences\n",
    "- minimize $\\sum^{N}_{i=1}\\epsilon_{i}^2 = \\sum^{N}_{i=1}(Y_{i} - Y_{esti}^2)$\n",
    "- works out nicely distribution-wise\n",
    "- you cna use calculus to get the estimates\n",
    "\n",
    "\n",
    "### Property of least squares\n",
    "\n",
    "Gauss Markow\n",
    "1. Assumptions\n",
    "- error has mean 0\n",
    "- things aren't correlated (homoscedasticity)\n",
    "- variance is the same for all observations\n",
    "\n",
    "2. *Unbiased* and have *lowest variance* among all unbiased estimators\n",
    "3. Best Linear Unbiased Estimator (BLUE)\n",
    "\n",
    "We don't need normality --> we need it only when estimating p-values\n",
    "\n",
    "\n",
    "### What about the variance?\n",
    "- we also need an estimate for $\\sigma^2$\n",
    "- start with the sim of squared error\n",
    "- $SSE = \\sum(Y_i - Y_esti)^2 = \\sum e_{i}^2$\n",
    "- divide by the appropriate degrees of freedom: # of independent pieces of information - # parameters in the model\n",
    "\n",
    "$\\sigma^2 = \\frac{\\sum e_{i}^2}{N-2}$\n",
    "\n",
    "### Multiple Linear Regression\n",
    "- Add more parameters to the model\n",
    "\n",
    "$Y_{i} = \\beta_{0} + \\beta_{1} X_{i} + \\beta_{2} X_{i} + \\beta_{3} X_{i} + \\epsilon_{i}$\n",
    "\n",
    "- Time for linear algebra!\n",
    "\n",
    "\n",
    "## Important stuff:\n",
    "\n",
    "- What parameters in the regression are considered \"fixed\"?\n",
    "- What parameters are considered \"random\"?\n",
    "- How do we define the \"best\" line?\n",
    "- How many parameters do you end up estimating in a simple linear regression\n",
    "- What is residual?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
